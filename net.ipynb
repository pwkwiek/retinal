{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285b3cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as L, Model\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, Precision, BinaryIoU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ca8f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d0f468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "def load_masks(mask_dir, image_size=(256, 256)):\n",
    "    mask_files = sorted(os.listdir(mask_dir))\n",
    "    masks = []\n",
    "\n",
    "    for mask_file in mask_files:\n",
    "        mask = cv2.imread(os.path.join(mask_dir, mask_file), cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.resize(mask, image_size)\n",
    "        mask = (mask / 255.0).astype(np.uint8)  # Ensure binary\n",
    "        masks.append(mask)\n",
    "\n",
    "    return np.expand_dims(np.array(masks, dtype=np.float32), -1)\n",
    "\n",
    "def load_images(image_dir, image_size=(256, 256)):\n",
    "    image_files = sorted(os.listdir(image_dir))\n",
    "    images = []\n",
    "\n",
    "    for img_file in image_files:\n",
    "        img = cv2.imread(os.path.join(image_dir, img_file), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, image_size) / 255.0\n",
    "        images.append(img)\n",
    "\n",
    "    return np.expand_dims(np.array(images, dtype=np.float32), -1)\n",
    "\n",
    "# Plotting\n",
    "def plot_image_mask(idx, X, Y, title=\"\"):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.imshow(X[idx].squeeze(), cmap='gray')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.imshow(Y[idx].squeeze(), cmap='gray')\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return 1 - (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def combined_dice_bce_loss(y_true, y_pred):\n",
    "    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    dice = dice_loss(y_true, y_pred)\n",
    "    return 0.4*bce + 0.6*dice\n",
    "\n",
    "# Model Blocks\n",
    "def conv_block(x, filters):\n",
    "    for _ in range(2):\n",
    "        x = L.Conv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = L.BatchNormalization()(x)\n",
    "        x = L.Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def encoder_block(x, filters):\n",
    "    c = conv_block(x, filters)\n",
    "    p = L.MaxPool2D((2, 2))(c)\n",
    "    return c, p\n",
    "\n",
    "def attention_gate(g, s, filters):\n",
    "    g1 = L.BatchNormalization()(L.Conv2D(filters, 1, padding=\"same\")(g))\n",
    "    s1 = L.BatchNormalization()(L.Conv2D(filters, 1, padding=\"same\")(s))\n",
    "    out = L.Activation(\"relu\")(g1 + s1)\n",
    "    out = L.Activation(\"sigmoid\")(L.Conv2D(filters, 1, padding=\"same\")(out))\n",
    "    return out * s\n",
    "\n",
    "def decoder_block(x, s, filters):\n",
    "    x = L.UpSampling2D(interpolation=\"bilinear\")(x)\n",
    "    s = attention_gate(x, s, filters)\n",
    "    x = L.Concatenate()([x, s])\n",
    "    return conv_block(x, filters)\n",
    "\n",
    "def attention_unet(input_shape):\n",
    "    inputs = L.Input(input_shape)\n",
    "    c0, p0 = encoder_block(inputs, 32)\n",
    "    c1, p1 = encoder_block(p0, 64)\n",
    "    c2, p2 = encoder_block(p1, 128)\n",
    "    c3, p3 = encoder_block(p2, 256)\n",
    "    c4, p4 = encoder_block(p3, 512)\n",
    "    c5 = conv_block(p4, 1024)\n",
    "    u1 = decoder_block(c5, c4, 512)\n",
    "    u2 = decoder_block(u1, c3, 256)\n",
    "    u3 = decoder_block(u2, c2, 128)\n",
    "    u4 = decoder_block(u3, c1, 64)\n",
    "    u5 = decoder_block(u4, c0, 32)\n",
    "    outputs = L.Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(u5)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    model.compile(optimizer=Adam(0.001),\n",
    "              loss=combined_dice_bce_loss,\n",
    "              metrics=[\n",
    "                  BinaryIoU(target_class_ids=[0, 1], threshold=0.5),\n",
    "                  BinaryAccuracy(),\n",
    "                  Precision()\n",
    "              ])\n",
    "\n",
    "    return model\n",
    "\n",
    "# -Metrics\n",
    "def plot_metrics(history, metric_name, ylabel, ylim=None):\n",
    "    plt.figure()\n",
    "    plt.plot(history.epoch, history.history[metric_name], 'b', label='Training')\n",
    "    plt.plot(history.epoch, history.history[f\"val_{metric_name}\"], 'r', label='Validation')\n",
    "    plt.title(f'Training and Validation {metric_name.capitalize()}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(ylabel)\n",
    "    if ylim:\n",
    "        plt.ylim(ylim)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Predict and Visualize Test Results\n",
    "def visualize_prediction(idx, model, X, Y):\n",
    "    pred = model.predict(np.expand_dims(X[idx], axis=0)).squeeze()\n",
    "    gt = Y[idx].squeeze()\n",
    "    diff = np.stack([gt, gt, pred], axis=-1)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.imshow(X[idx].squeeze(), cmap='gray')\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.imshow(gt, cmap='gray')\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.imshow(pred, cmap='gray')\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.title(\"Differences\")\n",
    "    plt.imshow(diff)\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate with DICE\n",
    "def DICE_COE(mask1, mask2):\n",
    "    intersect = np.sum(mask1 * mask2)\n",
    "    return round((2 * intersect) / (np.sum(mask1) + np.sum(mask2) + 1e-7), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ab30f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = ['gray', 'RGB_B', 'RGB_G', 'RGB_R', 'YUV_Y', 'YUV_U', 'YUV_V',\n",
    "            'HSV_H', 'HSV_S', 'HSV_V', 'HLS_H', 'HLS_L', 'HLS_S',\n",
    "            'CIELab_L', 'CIELab_a', 'CIELab_b', 'YCrCb_Y', 'YCrCb_Cr', 'YCrCb_Cb']\n",
    "\n",
    "# Common target mask directories\n",
    "mask_train_dir = 'C:/Users/User/Desktop/Helevorn/data/segmentation/train'\n",
    "mask_val_dir = 'C:/Users/User/Desktop/Helevorn/data/segmentation/val'\n",
    "mask_test_dir = 'C:/Users/User/Desktop/Helevorn/data/segmentation/test'\n",
    "\n",
    "Y_train = load_masks(mask_train_dir)\n",
    "Y_val = load_masks(mask_val_dir)\n",
    "Y_test = load_masks(mask_test_dir)\n",
    "\n",
    "for channel in channels:\n",
    "    print(f\"\\n--- Processing Channel: {channel} ---\")\n",
    "    \n",
    "    img_train_dir = f'C:/Users/User/Desktop/Helevorn/data/chan/{channel}/images/train'\n",
    "    img_val_dir = f'C:/Users/User/Desktop/Helevorn/data/chan/{channel}/images/val'\n",
    "    img_test_dir = f'C:/Users/User/Desktop/Helevorn/data/chan/{channel}/images/test'\n",
    "    \n",
    "    # Load channel-specific input images\n",
    "    X_train = load_images(img_train_dir)\n",
    "    X_val = load_images(img_val_dir)\n",
    "    X_test = load_images(img_test_dir)\n",
    "    \n",
    "    print(f\"Train shape: {X_train.shape}, Val shape: {X_val.shape}, Test shape: {X_test.shape}\")\n",
    "    \n",
    "    model = attention_unet((256, 256, 1))\n",
    "    \n",
    "    history = model.fit(X_train, Y_train,\n",
    "                        validation_data=(X_val, Y_val),\n",
    "                        batch_size=8,\n",
    "                        epochs=50)\n",
    "    \n",
    "    # Plot metrics\n",
    "    plot_metrics(history, 'binary_accuracy', 'Binary Accuracy', [0, 1])\n",
    "    plot_metrics(history, 'precision', 'Precision', [0, 1])\n",
    "    plot_metrics(history, 'loss', 'Loss', [0, 1])\n",
    "    plot_metrics(history, 'binary_io_u', 'IoU', [0, 1])\n",
    "    \n",
    "    # Evaluate and print DICE\n",
    "    dice_scores = [DICE_COE(model.predict(np.expand_dims(x, 0)).squeeze(), y.squeeze())\n",
    "                   for x, y in zip(X_test, Y_test)]\n",
    "\n",
    "    print(f\"{channel} - Avg DICE Score:\", np.mean(dice_scores))\n",
    "    print(f\"{channel} - Max DICE Score:\", np.max(dice_scores))\n",
    "    print(f\"{channel} - Min DICE Score:\", np.min(dice_scores))\n",
    "    print(f\"{channel} - Std DICE Score:\", np.std(dice_scores))\n",
    "    \n",
    "    # Save model\n",
    "    model.save(f'retinal_{channel}.keras')\n",
    "\n",
    "    # Cleanup\n",
    "    del X_train, X_val, X_test, model\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ab6574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_unet(input_shape=(None, None, 1)):\n",
    "    inputs = L.Input(input_shape)\n",
    "    c0, p0 = encoder_block(inputs, 32)\n",
    "    c1, p1 = encoder_block(p0, 64)\n",
    "    c2, p2 = encoder_block(p1, 128)\n",
    "    c3, p3 = encoder_block(p2, 256)\n",
    "    c4, p4 = encoder_block(p3, 512)\n",
    "    c5 = conv_block(p4, 1024)\n",
    "    u1 = decoder_block(c5, c4, 512)\n",
    "    u2 = decoder_block(u1, c3, 256)\n",
    "    u3 = decoder_block(u2, c2, 128)\n",
    "    u4 = decoder_block(u3, c1, 64)\n",
    "    u5 = decoder_block(u4, c0, 32)\n",
    "    outputs = L.Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(u5)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    model.compile(optimizer=Adam(0.001),\n",
    "              loss=combined_dice_bce_loss,\n",
    "              metrics=[\n",
    "                  BinaryIoU(target_class_ids=[0, 1], threshold=0.5),\n",
    "                  BinaryAccuracy(),\n",
    "                  Precision()\n",
    "              ])\n",
    "\n",
    "    return model\n",
    "\n",
    "for channel in channels:\n",
    "    model_path = f\"retinal_{channel}.keras\"\n",
    "    weights_path = f\"model_weights_{channel}.h5\"\n",
    "    \n",
    "    print(f\"Processing {channel}...\")\n",
    "\n",
    "    # Load fixed model with locked input shape\n",
    "    fixed_model = load_model(\n",
    "        model_path,\n",
    "        custom_objects={\n",
    "            \"combined_dice_bce_loss\": combined_dice_bce_loss,\n",
    "            \"dice_loss\": dice_loss,\n",
    "            \"BinaryIoU\": tf.keras.metrics.BinaryIoU,\n",
    "            \"BinaryAccuracy\": tf.keras.metrics.BinaryAccuracy,\n",
    "            \"Precision\": tf.keras.metrics.Precision\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Save weights only\n",
    "    fixed_model.save_weights(weights_path)\n",
    "    print(f\"Saved weights to {weights_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7600ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    y_true = y_true.flatten()\n",
    "    y_pred = y_pred.flatten()\n",
    "\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn + 1e-6)\n",
    "    prec = tp / (tp + fp + 1e-6)\n",
    "    spec = tn / (tn + fp + 1e-6)\n",
    "\n",
    "    return acc, prec, spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526ef94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild the flexible model\n",
    "flex_model = attention_unet(input_shape=(None, None, 1))\n",
    "\n",
    "# Load weights\n",
    "flex_model.load_weights(\"model_weights_gray.h5\")\n",
    "\n",
    "# Load and preprocess image\n",
    "img_path = \"C:/Users/User/Desktop/Fangorn/data/numeric/images/grey/1.png\"\n",
    "img = load_img(img_path, color_mode=\"grayscale\")\n",
    "img = img_to_array(img)  # shape: (H, W, 1)\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "# Pad to multiple of 32\n",
    "pad_h = (32 - h % 32) % 32\n",
    "pad_w = (32 - w % 32) % 32\n",
    "img_padded = np.pad(img, ((0, pad_h), (0, pad_w), (0, 0)), mode=\"constant\")\n",
    "\n",
    "img_padded = img_padded / 255.0\n",
    "img_input = np.expand_dims(img_padded, axis=0)  # (1, H, W, 1)\n",
    "\n",
    "# Predict\n",
    "pred = flex_model.predict(img_input)[0, ..., 0]\n",
    "pred = pred[:h, :w]  # Crop back to original size\n",
    "\n",
    "# Threshold\n",
    "binary_mask = (pred > 0.5).astype(np.uint8)\n",
    "\n",
    "# Load ground truth mask (must match predicted shape)\n",
    "gt_mask = load_img(\"C:/Users/User/Desktop/Fangorn/data/numeric/gt/1.png\", color_mode=\"grayscale\")\n",
    "gt_mask = img_to_array(gt_mask).squeeze()  # shape: (H, W)\n",
    "gt_mask = cv2.resize(gt_mask, (w, h))  # Resize if needed\n",
    "gt_mask = (gt_mask > 127).astype(np.uint8)  # Binarize if it's 8-bit\n",
    "\n",
    "dice_score = DICE_COE(gt_mask, binary_mask)\n",
    "\n",
    "acc, prec, spec = calculate_metrics(gt_mask, binary_mask)\n",
    "\n",
    "print(f\"Dice coefficient : {dice_score:.4f}\")\n",
    "print(f\"Accuracy         : {acc:.4f}\")\n",
    "print(f\"Precision        : {prec:.4f}\")\n",
    "print(f\"Specificity      : {spec:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(gt_mask, cmap=\"gray\")\n",
    "plt.title(\"Ground Truth Mask\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(binary_mask, cmap=\"gray\")\n",
    "plt.title(f\"Predicted Mask Dice: {dice_score:.4f}\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smaug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
